{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a527cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import districting_methods\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import concurrent\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9e5f4",
   "metadata": {},
   "source": [
    "* `poland` - shapefile of Poland\n",
    "* `graph` - graph of Poland's voting districts (adjency list based on Voronoi algorithm - details can be found in `shapefiles/wybory2019_voronoi`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75bb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poland = gpd.read_file(\"shapefiles/polska/polska.shp\", encoding=\"utf-8\")\n",
    "graph = nx.read_gexf(\"pickle_files/wybory2019sejm_graph_without_parties.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600077d",
   "metadata": {},
   "source": [
    "#### The following cell is optional\n",
    "If you want to carry out the coarsening of the graph (reduce the number of nodes by merging some adjacent nodes), run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5853c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarsening iteration 1/1\n",
      "Coarsening progress:  0.32781228433402343 %\n",
      "Coarsening progress:  0.6987577639751553 %\n",
      "Coarsening progress:  5.0983436853002075 %\n",
      "Coarsening progress:  5.52967563837129 %\n",
      "Coarsening progress:  5.952380952380952 %\n",
      "Coarsening progress:  10.153554175293305 %\n",
      "Coarsening progress:  10.584886128364388 %\n",
      "Coarsening progress:  15.260524499654935 %\n",
      "Coarsening progress:  15.683229813664596 %\n",
      "Coarsening progress:  20.324361628709458 %\n",
      "Coarsening progress:  20.755693581780537 %\n",
      "Coarsening progress:  25.0 %\n",
      "Coarsening progress:  25.431331953071084 %\n",
      "Coarsening progress:  25.86266390614217 %\n",
      "Coarsening progress:  30.158730158730158 %\n",
      "Coarsening progress:  30.59006211180124 %\n",
      "Coarsening progress:  35.317460317460316 %\n",
      "Coarsening progress:  35.748792270531396 %\n",
      "Coarsening progress:  40.01897860593513 %\n",
      "Coarsening progress:  40.441683919944786 %\n",
      "Coarsening progress:  40.86438923395445 %\n",
      "Coarsening progress:  45.09144237405107 %\n",
      "Coarsening progress:  45.52277432712215 %\n",
      "Coarsening progress:  45.95410628019324 %\n",
      "Coarsening progress:  50.24154589371981 %\n",
      "Coarsening progress:  50.67287784679089 %\n",
      "Coarsening progress:  55.36576949620427 %\n",
      "Coarsening progress:  55.79710144927537 %\n",
      "Coarsening progress:  60.02415458937198 %\n",
      "Coarsening progress:  60.45548654244306 %\n",
      "Coarsening progress:  60.86956521739131 %\n",
      "Coarsening progress:  65.1311249137336 %\n",
      "Coarsening progress:  65.5624568668047 %\n",
      "Coarsening progress:  65.98516218081436 %\n",
      "Coarsening progress:  70.22946859903382 %\n",
      "Coarsening progress:  70.6608005521049 %\n",
      "Coarsening progress:  75.32781228433403 %\n",
      "Coarsening progress:  75.75051759834368 %\n",
      "Coarsening progress:  80.00345065562456 %\n",
      "Coarsening progress:  80.41752933057282 %\n",
      "Coarsening progress:  80.84886128364388 %\n",
      "Coarsening progress:  85.10179434092477 %\n",
      "Coarsening progress:  85.53312629399586 %\n",
      "Coarsening progress:  85.96445824706694 %\n",
      "Coarsening progress:  90.23464458247066 %\n",
      "Coarsening progress:  90.65734989648033 %\n",
      "Coarsening progress:  95.31573498964804 %\n",
      "Coarsening progress:  95.7384403036577 %\n",
      "Coarsening progress:  100.00862663906143 %\n"
     ]
    }
   ],
   "source": [
    "graph = districting_methods.graph_coarsening(graph, decrease_percent=0.5, num_of_iterations=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60120813",
   "metadata": {},
   "source": [
    "Preparing geopandas frame (no matter if you've coarsend or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d2ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"shapefiles/wybory2019_voronoi/wybory2019sejm_voronoi.shx\", encoding=\"utf-8\")\n",
    "gdf = gdf[['teryt', 'obwod', 'geometry']]\n",
    "gdf['id'] = gdf['teryt'] + '_' + gdf['obwod'].astype(str)\n",
    "\n",
    "simple_id_to_graph_node_map = {}\n",
    "for graph_node in graph.nodes:\n",
    "    simple_ids = graph_node.split('+')\n",
    "    for simple_id in simple_ids:\n",
    "        simple_id_to_graph_node_map[simple_id] = graph_node\n",
    "\n",
    "gdf['graph_node_id'] = gdf['id'].map(simple_id_to_graph_node_map)\n",
    "unmapped_rows = gdf[gdf['graph_node_id'].isnull()]\n",
    "if not unmapped_rows.empty:\n",
    "    print(f\"\\nUWAGA: Nie znaleziono mapowania dla {len(unmapped_rows)} wierszy. ID, których nie było w grafie:\")\n",
    "    print(unmapped_rows['id'].unique())\n",
    "gdf_dissolved = gdf.dissolve(by='graph_node_id', as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ca7c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OF_THREADS = 5 # number of threads to use in parallel computations\n",
    "n_districts = 100 # number of districts to create\n",
    "hot_steps = 10 # number of hot steps in simulated annealing\n",
    "annealing_steps = 10 # number of annealing steps in simulated annealing\n",
    "cold_steps = 500 # number of cold steps in simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b0b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_redist_flip_alg(beta_eq_pop_target, beta_compactness_target, initial_seeding_attempts = 20, initial_districting = None, i=0):\n",
    "        print(f\"Running redist_flip_alg with thread {i + 1}/{N_OF_THREADS}\")\n",
    "        result, data = districting_methods.redist_flip_alg(\n",
    "            graph, gdf_dissolved, poland, number_of_districts = n_districts,\n",
    "            hot_steps = hot_steps, annealing_steps = annealing_steps, cold_steps = cold_steps,\n",
    "            lambda_prob=0.1, beta_eq_pop_target=beta_eq_pop_target, beta_compactness_target=beta_compactness_target, initial_seeding_attempts = initial_seeding_attempts, initial_districts = initial_districting\n",
    "        )\n",
    "        print(f\"Finished redist_flip_alg with thread {i}/{N_OF_THREADS}\")\n",
    "        if not os.path.exists(\"results\"):\n",
    "            os.makedirs(\"results\")\n",
    "        if os.path.exists(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}.pkl\") or os.path.exists(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}.pkl\"):\n",
    "            index = 1\n",
    "            while os.path.exists(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\") or os.path.exists(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\"):\n",
    "                index += 1\n",
    "            pkl.dump(result, open(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\", \"wb\"))\n",
    "            pkl.dump(data, open(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\", \"wb\"))\n",
    "        else:\n",
    "            pkl.dump(result, open(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}.pkl\", \"wb\"))\n",
    "            pkl.dump(data, open(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8f9be",
   "metadata": {},
   "source": [
    "Here you can set parameters for the algorithm. Each tuple in a list is a separate job that will be run in parallel. Pair is in format: \n",
    "\n",
    "(`beta_eq_pop_target, beta_compactness_target, initial_seeding_attempts, initial_districting`)\n",
    "\n",
    "* higher `beta_eq_pop_target` means that the algorithm will prioritize equal population more\n",
    "* higher `beta_compactness_target` means that the algorithm will prioritize compactness more\n",
    "* `initial_seeding_attempts` - number of attempts to create initial districting (algorithm creates initial districting randomly, and then picks the best one - 20 by default)\n",
    "* `initial_districting` - if you want to provide your own initial districting (fe. from previous run), provide it here. If provided, `initial_seeding_attempts` is ignored. By default, results are saved in `results` folder with filenames indicating the parameters used. If you want to use `initial_seeding_attempts`, set `initial_districting` to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5279316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage with initial_districting:\n",
    "initial_districting = pkl.load(open(\"results/redist_flip_alg_result_3100_3020.pkl\", \"rb\"))\n",
    "job_params = [(3100, 3020, 0, initial_districting)]\n",
    "## Additionaly - I would suggest changing values of hot_steps, annealing_steps and cold_steps accordingly\n",
    "## If you are using initial_districting, then I would suggest lowering number of hot_steps and annealing_steps\n",
    "## That is because if algorithm is in hot phase or annealing phase, it has higher chance of doing random changes, even when they aren't benefitial\n",
    "## and when you're using initial_districting, I would assume you want to make it better, not change it randomly\n",
    "## So, for example, for seeding attempts use:\n",
    "    # hot_steps, annealing_steps, cold_steps = 500, 300, 1000\n",
    "## And with initial_districting change that to fe:\n",
    "    # hot_steps, annealing_steps, cold_steps = 50, 30, 10000\n",
    "\n",
    "# job_params = [(3100, 3020, 10, None), (3000, 2700, 10, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0022f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running redist_flip_alg with thread 1/5\n",
      "Old Population Max Derivative: 0.9746384813158776\n",
      "Old Population Average Derivative: 0.2927983800731231\n",
      "New Population Max Derivative: 0.9746384813158776\n",
      "New Population Average Derivative: 15.577614551493957\n",
      "Starting redistricting algorithm with 100 districts, hot steps: 10, annealing steps: 10, cold steps: 500, lambda probability: 0.1\n",
      "Step 100/520\n",
      "Avg Derivation: 15.442116330900848, Compactness: 72.26352608464727\n",
      "Accepted: 36, Rejected: 64\n",
      "pop_target: 3100.0, comp_target: 3020.0\n",
      "Step 200/520\n",
      "Avg Derivation: 15.143709249650154, Compactness: 72.30258930245463\n",
      "Accepted: 39, Rejected: 61\n",
      "pop_target: 3100.0, comp_target: 3020.0\n",
      "Step 300/520\n",
      "Avg Derivation: 14.951446238239798, Compactness: 72.48237162975528\n",
      "Accepted: 35, Rejected: 65\n",
      "pop_target: 3100.0, comp_target: 3020.0\n",
      "Step 400/520\n",
      "Avg Derivation: 14.784679763436065, Compactness: 72.54151233096889\n",
      "Accepted: 25, Rejected: 75\n",
      "pop_target: 3100.0, comp_target: 3020.0\n",
      "Step 500/520\n",
      "Avg Derivation: 14.611705815013837, Compactness: 72.65514215518192\n",
      "Accepted: 37, Rejected: 63\n",
      "pop_target: 3100.0, comp_target: 3020.0\n",
      "Final Avg Derivation: 14.606160287543764, Final Compactness: 72.65246524796936, Final Max Derivation: 0.9746384813158776\n",
      " beta_eq_pop_target: 3100.0, beta_compactness_target: 3020.0\n",
      "Finished redist_flip_alg with thread 0/5\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=N_OF_THREADS) as executor:\n",
    "    futures = [executor.submit(run_redist_flip_alg, beta_eq, beta_comp, init_seed, init_dist, i) for i, (beta_eq, beta_comp, init_seed, init_dist) in enumerate(job_params)]\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'An exception has been raised: {exc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
