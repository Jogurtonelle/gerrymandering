{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import districting_methods\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import concurrent\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9e5f4",
   "metadata": {},
   "source": [
    "* `poland` - shapefile of Poland\n",
    "* `graph` - graph of Poland's voting districts (adjency list based on Voronoi algorithm - details can be found in `shapefiles/wybory2019_voronoi`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75bb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poland = gpd.read_file(\"shapefiles/polska/polska.shp\", encoding=\"utf-8\")\n",
    "graph = nx.read_gexf(\"pickle_files/wybory2019sejm_graph_without_parties.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600077d",
   "metadata": {},
   "source": [
    "#### The following cell is optional\n",
    "If you want to carry out the coarsening of the graph (reduce the number of nodes by merging some adjacent nodes), run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = districting_methods.graph_coarsening(graph, decrease_percent=0.5, num_of_iterations=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60120813",
   "metadata": {},
   "source": [
    "Preparing geopandas frame (no matter if you've coarsend or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"shapefiles/wybory2019_voronoi/wybory2019sejm_voronoi.shx\", encoding=\"utf-8\")\n",
    "gdf = gdf[['teryt', 'obwod', 'geometry']]\n",
    "gdf['id'] = gdf['teryt'] + '_' + gdf['obwod'].astype(str)\n",
    "\n",
    "simple_id_to_graph_node_map = {}\n",
    "for graph_node in graph.nodes:\n",
    "    simple_ids = graph_node.split('+')\n",
    "    for simple_id in simple_ids:\n",
    "        simple_id_to_graph_node_map[simple_id] = graph_node\n",
    "\n",
    "gdf['graph_node_id'] = gdf['id'].map(simple_id_to_graph_node_map)\n",
    "unmapped_rows = gdf[gdf['graph_node_id'].isnull()]\n",
    "if not unmapped_rows.empty:\n",
    "    print(f\"\\nUWAGA: Nie znaleziono mapowania dla {len(unmapped_rows)} wierszy. ID, których nie było w grafie:\")\n",
    "    print(unmapped_rows['id'].unique())\n",
    "gdf_dissolved = gdf.dissolve(by='graph_node_id', as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OF_THREADS = 5 # number of threads to use in parallel computations\n",
    "n_districts = 100 # number of districts to create\n",
    "hot_steps = 500 # number of hot steps in simulated annealing\n",
    "annealing_steps = 300 # number of annealing steps in simulated annealing\n",
    "cold_steps = 1000 # number of cold steps in simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_redist_flip_alg(beta_eq_pop_target, beta_compactness_target, initial_seeding_attempts = 20, initial_districting = None, i=0):\n",
    "        print(f\"Running redist_flip_alg with thread {i + 1}/{N_OF_THREADS}\")\n",
    "        result, data = districting_methods.redist_flip_alg(\n",
    "            graph, gdf_dissolved, poland, number_of_districts = n_districts,\n",
    "            hot_steps = hot_steps, annealing_steps = annealing_steps, cold_steps = cold_steps,\n",
    "            lambda_prob=0.1, beta_eq_pop_target=beta_eq_pop_target, beta_compactness_target=beta_compactness_target, initial_seeding_attempts = initial_seeding_attempts, initial_districts = initial_districting\n",
    "        )\n",
    "        print(f\"Finished redist_flip_alg with thread {i}/{N_OF_THREADS}\")\n",
    "        if not os.path.exists(\"results\"):\n",
    "            os.makedirs(\"results\")\n",
    "        if os.path.exists(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}.pkl\") or os.path.exists(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}.pkl\"):\n",
    "            index = 1\n",
    "            while os.path.exists(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\") or os.path.exists(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\"):\n",
    "                index += 1\n",
    "            pkl.dump(result, open(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\", \"wb\"))\n",
    "            pkl.dump(data, open(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\", \"wb\"))\n",
    "        else:\n",
    "            pkl.dump(result, open(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}.pkl\", \"wb\"))\n",
    "            pkl.dump(data, open(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8f9be",
   "metadata": {},
   "source": [
    "Here you can set parameters for the algorithm. Each tuple in a list is a separate job that will be run in parallel. Pair is in format: \n",
    "\n",
    "(`beta_eq_pop_target, beta_compactness_target, initial_seeding_attempts, initial_districting`)\n",
    "\n",
    "* higher `beta_eq_pop_target` means that the algorithm will prioritize equal population more\n",
    "* higher `beta_compactness_target` means that the algorithm will prioritize compactness more\n",
    "* `initial_seeding_attempts` - number of attempts to create initial districting (algorithm creates initial districting randomly, and then picks the best one - 20 by default)\n",
    "* `initial_districting` - if you want to provide your own initial districting (fe. from previous run), provide it here. If provided, `initial_seeding_attempts` is ignored. By default, results are saved in `results` folder with filenames indicating the parameters used. If you want to use `initial_seeding_attempts`, set `initial_districting` to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage with initial_districting:\n",
    "    # initial_districting = pkl.load(open(\"results/redist_flip_alg_result_3100_3020.pkl\", \"rb\"))\n",
    "    # job_params = [(3100, 3020, 0, initial_districting)]\n",
    "## Additionaly - I would suggest changing values of hot_steps, annealing_steps and cold_steps accordingly\n",
    "## If you are using initial_districting, then I would suggest lowering number of hot_steps and annealing_steps\n",
    "## That is because if algorithm is in hot phase or annealing phase, it has higher chance of doing random changes, even when they aren't benefitial\n",
    "## and when you're using initial_districting, I would assume you want to make it better, not change it randomly\n",
    "## So, for example, for seeding attempts use:\n",
    "    # hot_steps, annealing_steps, cold_steps = 500, 300, 1000\n",
    "## And with initial_districting change that to fe:\n",
    "    # hot_steps, annealing_steps, cold_steps = 50, 30, 10000\n",
    "\n",
    "job_params = [(3100, 3020, 10, None), (3000, 2700, 10, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0022f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=N_OF_THREADS) as executor:\n",
    "    futures = [executor.submit(run_redist_flip_alg, beta_eq, beta_comp, init_seed, init_dist, i) for i, (beta_eq, beta_comp, init_seed, init_dist) in enumerate(job_params)]\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'An exception has been raised: {exc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
