{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a527cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import districting_methods\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import concurrent\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9e5f4",
   "metadata": {},
   "source": [
    "* `poland` - shapefile of Poland\n",
    "* `graph` - graph of Poland's voting districts (adjency list based on Voronoi algorithm - details can be found in `shapefiles/wybory2019_voronoi`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75bb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poland = gpd.read_file(\"shapefiles/polska/polska.shp\", encoding=\"utf-8\")\n",
    "graph = nx.read_gexf(\"pickle_files/wybory2019sejm_graph_without_parties.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600077d",
   "metadata": {},
   "source": [
    "#### The following cell is optional\n",
    "If you want to carry out the coarsening of the graph (reduce the number of nodes by merging some adjacent nodes), run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5853c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarsening iteration 1/1\n",
      "Coarsening progress:  0.3105590062111801 %\n",
      "Coarsening progress:  0.6556245686680469 %\n",
      "Coarsening progress:  5.391649413388544 %\n",
      "Coarsening progress:  5.805728088336784 %\n",
      "Coarsening progress:  10.412353347135955 %\n",
      "Coarsening progress:  10.84368530020704 %\n",
      "Coarsening progress:  15.053485162180813 %\n",
      "Coarsening progress:  15.484817115251898 %\n",
      "Coarsening progress:  15.916149068322982 %\n",
      "Coarsening progress:  20.18633540372671 %\n",
      "Coarsening progress:  20.617667356797792 %\n",
      "Coarsening progress:  25.293305728088338 %\n",
      "Coarsening progress:  25.724637681159418 %\n",
      "Coarsening progress:  30.400276052449964 %\n",
      "Coarsening progress:  30.814354727398207 %\n",
      "Coarsening progress:  35.06728778467909 %\n",
      "Coarsening progress:  35.49861973775017 %\n",
      "Coarsening progress:  35.929951690821255 %\n",
      "Coarsening progress:  40.19151138716356 %\n",
      "Coarsening progress:  40.61421670117322 %\n",
      "Coarsening progress:  45.30710835058661 %\n",
      "Coarsening progress:  45.7384403036577 %\n",
      "Coarsening progress:  50.414078674948236 %\n",
      "Coarsening progress:  50.84541062801933 %\n",
      "Coarsening progress:  55.106970324361626 %\n",
      "Coarsening progress:  55.52967563837129 %\n",
      "Coarsening progress:  55.952380952380956 %\n",
      "Coarsening progress:  60.21394064872325 %\n",
      "Coarsening progress:  60.6280193236715 %\n",
      "Coarsening progress:  65.34679089026915 %\n",
      "Coarsening progress:  65.76949620427881 %\n",
      "Coarsening progress:  70.01380262249828 %\n",
      "Coarsening progress:  70.44513457556936 %\n",
      "Coarsening progress:  70.87646652864045 %\n",
      "Coarsening progress:  75.13802622498275 %\n",
      "Coarsening progress:  75.56935817805382 %\n",
      "Coarsening progress:  80.22774327122153 %\n",
      "Coarsening progress:  80.65907522429262 %\n",
      "Coarsening progress:  85.34334023464459 %\n",
      "Coarsening progress:  85.77467218771567 %\n",
      "Coarsening progress:  90.06211180124224 %\n",
      "Coarsening progress:  90.47619047619048 %\n",
      "Coarsening progress:  90.89026915113871 %\n",
      "Coarsening progress:  95.16045548654245 %\n",
      "Coarsening progress:  95.59178743961353 %\n",
      "Coarsening progress:  100.30193236714975 %\n"
     ]
    }
   ],
   "source": [
    "graph = districting_methods.graph_coarsening(graph, decrease_percent=0.5, num_of_iterations=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60120813",
   "metadata": {},
   "source": [
    "Preparing geopandas frame (no matter if you've coarsend or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d2ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"shapefiles/wybory2019_voronoi/wybory2019sejm_voronoi.shx\", encoding=\"utf-8\")\n",
    "gdf = gdf[['teryt', 'obwod', 'geometry']]\n",
    "gdf['id'] = gdf['teryt'] + '_' + gdf['obwod'].astype(str)\n",
    "\n",
    "simple_id_to_graph_node_map = {}\n",
    "for graph_node in graph.nodes:\n",
    "    simple_ids = graph_node.split('+')\n",
    "    for simple_id in simple_ids:\n",
    "        simple_id_to_graph_node_map[simple_id] = graph_node\n",
    "\n",
    "gdf['graph_node_id'] = gdf['id'].map(simple_id_to_graph_node_map)\n",
    "unmapped_rows = gdf[gdf['graph_node_id'].isnull()]\n",
    "if not unmapped_rows.empty:\n",
    "    print(f\"\\nUWAGA: Nie znaleziono mapowania dla {len(unmapped_rows)} wierszy. ID, których nie było w grafie:\")\n",
    "    print(unmapped_rows['id'].unique())\n",
    "gdf_dissolved = gdf.dissolve(by='graph_node_id', as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OF_THREADS = 5 # number of threads to use in parallel computations\n",
    "n_districts = 100 # number of districts to create\n",
    "hot_steps = 500 # number of hot steps in simulated annealing\n",
    "annealing_steps = 300 # number of annealing steps in simulated annealing\n",
    "cold_steps = 1000 # number of cold steps in simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b0b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_redist_flip_alg(beta_eq_pop_target, beta_compactness_target, initial_seeding_attempts = 20, initial_districting = None, i=0):\n",
    "        print(f\"Running redist_flip_alg with thread {i + 1}/{N_OF_THREADS}\")\n",
    "        result, data = districting_methods.redist_flip_alg(\n",
    "            graph, gdf_dissolved, poland, number_of_districts = n_districts,\n",
    "            hot_steps = hot_steps, annealing_steps = annealing_steps, cold_steps = cold_steps,\n",
    "            lambda_prob=0.1, beta_eq_pop_target=beta_eq_pop_target, beta_compactness_target=beta_compactness_target, initial_seeding_attempts = initial_seeding_attempts, initial_districts = initial_districting\n",
    "        )\n",
    "        print(f\"Finished redist_flip_alg with thread {i}/{N_OF_THREADS}\")\n",
    "        if not os.path.exists(\"results\"):\n",
    "            os.makedirs(\"results\")\n",
    "        if os.path.exists(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}.pkl\") or os.path.exists(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}.pkl\"):\n",
    "            index = 1\n",
    "            while os.path.exists(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\") or os.path.exists(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\"):\n",
    "                index += 1\n",
    "            pkl.dump(result, open(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\", \"wb\"))\n",
    "            pkl.dump(data, open(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}_{index}.pkl\", \"wb\"))\n",
    "        else:\n",
    "            pkl.dump(result, open(f\"results/redist_flip_alg_result_{beta_eq_pop_target}_{beta_compactness_target}.pkl\", \"wb\"))\n",
    "            pkl.dump(data, open(f\"results/redist_flip_alg_data_{beta_eq_pop_target}_{beta_compactness_target}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8f9be",
   "metadata": {},
   "source": [
    "Here you can set parameters for the algorithm. Each tuple in a list is a separate job that will be run in parallel. Pair is in format: \n",
    "\n",
    "(`beta_eq_pop_target, beta_compactness_target, initial_seeding_attempts, initial_districting`)\n",
    "\n",
    "* higher `beta_eq_pop_target` means that the algorithm will prioritize equal population more\n",
    "* higher `beta_compactness_target` means that the algorithm will prioritize compactness more\n",
    "* `initial_seeding_attempts` - number of attempts to create initial districting (algorithm creates initial districting randomly, and then picks the best one - 20 by default)\n",
    "* `initial_districting` - if you want to provide your own initial districting (fe. from previous run), provide it here. If provided, `initial_seeding_attempts` is ignored. By default, results are saved in `results` folder with filenames indicating the parameters used. If you want to use `initial_seeding_attempts`, set `initial_districting` to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5279316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage with initial_districting:\n",
    "    # initial_districting = pkl.load(open(\"results/redist_flip_alg_result_3100_3020.pkl\", \"rb\"))\n",
    "    # job_params = [(3100, 3020, 0, initial_districting)]\n",
    "## Additionaly - I would suggest changing values of hot_steps, annealing_steps and cold_steps accordingly\n",
    "## If you are using initial_districting, then I would suggest lowering number of hot_steps and annealing_steps\n",
    "## That is because if algorithm is in hot phase or annealing phase, it has higher chance of doing random changes, even when they aren't benefitial\n",
    "## and when you're using initial_districting, I would assume you want to make it better, not change it randomly\n",
    "## So, for example, for seeding attempts use:\n",
    "    # hot_steps, annealing_steps, cold_steps = 500, 300, 1000\n",
    "## And with initial_districting change that to fe:\n",
    "    # hot_steps, annealing_steps, cold_steps = 50, 30, 10000\n",
    "\n",
    "job_params = [(3100, 3020, 10, None), (3000, 2700, 10, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0022f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running redist_flip_alg with thread 1/5Running redist_flip_alg with thread 2/5\n",
      "\n",
      "Finding the best initial seeding out of 10 attempts...\n",
      "Finding the best initial seeding out of 10 attempts...\n",
      "Error in seeding algorithm: Unexpected error in seeding algorithm - node is not connected to any of the covered nodes. Retrying...\n",
      "Starting redistricting algorithm with 100 districts, hot steps: 10, annealing steps: 10, cold steps: 100, lambda probability: 0.1, beta_eq_pop_target: 3000, beta_compactness_target: 2700\n",
      "Failed to divide the largest district into two connected subgraphs after 20 attempts.\n",
      "Starting redistricting algorithm with 100 districts, hot steps: 10, annealing steps: 10, cold steps: 100, lambda probability: 0.1, beta_eq_pop_target: 3100, beta_compactness_target: 3020\n",
      "Step 100/120\n",
      "Avg Derivation: 17.719658552696586, Compactness: 73.60737266846715\n",
      "Accepted: 45, Rejected: 55\n",
      "pop_target: 3000.0, comp_target: 2700.0\n",
      "Final Avg Derivation: 17.64004509550494, Final Compactness: 73.54539971863716, Final Max Derivation: 0.99679302526133\n",
      " beta_eq_pop_target: 3000.0, beta_compactness_target: 2700.0\n",
      "Finished redist_flip_alg with thread 1/5\n",
      "Step 100/120\n",
      "Avg Derivation: 14.643600933102904, Compactness: 72.38121577478384\n",
      "Accepted: 50, Rejected: 50\n",
      "pop_target: 3100.0, comp_target: 3020.0\n",
      "Final Avg Derivation: 14.628274889662956, Final Compactness: 72.37513110945834, Final Max Derivation: 0.9510426379831814\n",
      " beta_eq_pop_target: 3100.0, beta_compactness_target: 3020.0\n",
      "Finished redist_flip_alg with thread 0/5\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=N_OF_THREADS) as executor:\n",
    "    futures = [executor.submit(run_redist_flip_alg, beta_eq, beta_comp, init_seed, init_dist, i) for i, (beta_eq, beta_comp, init_seed, init_dist) in enumerate(job_params)]\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'An exception has been raised: {exc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
